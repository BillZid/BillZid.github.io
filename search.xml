<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python</title>
      <link href="/python/"/>
      <url>/python/</url>
      
        <content type="html"><![CDATA[<ol><li><p>求数组某行某列的最大值(最小值)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求所有数字中的最大值</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一列的最大值组成列表</span><span class="token triple-quoted-string string">'''对a=a[n0][n1],axis=0时,对应n0已经确定下来,即n0取值定为0,1,遍历n0.所以此时的amax就是固定n1,amax[n1] = max(a[0][n1],a[1][n1]),表现为按列取最大值'''</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一行的最大值组成列表</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">5[2 5][5 3]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>矩阵点积与向量外积</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>d <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 就是数学上的矩阵乘法</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>c<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token triple-quoted-string string">'''向量外积,也就是m维向量和n维向量之间,做(m,1)和(1,n)到(m,n)的矩阵乘法,有效解决numpy中(k,)维向量的歧义'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">[[15 20] [11 16]][[ 6 15] [ 8 20]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>矩阵(多维数组)求和</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 所有维度求和</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一列的和</span><span class="token triple-quoted-string string">'''对a=a[n0][n1],axis=0时,对应n0已经确定下来,即n0取值定为0,1,遍历n0.所以此时的sum就是固定n1,sum[n1] = a[0][n1]+a[1][n1],表现为按列求和'''</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一行的和</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">10[2 8][5 5]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 自学笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>复杂系统与复杂网络</title>
      <link href="/fu-za-xi-tong-yu-fu-za-wang-luo/"/>
      <url>/fu-za-xi-tong-yu-fu-za-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h2><p>参考用书<br>1、Networks Crowds and Markets: Reasoning about a Highly Connected World David Easley and Jon Kleinberg 2010年 Cambridge University Press</p><p>课程教师信息<br>课程首席教授郑晓龙研究员，在社会计算、知识图谱和大数据解析学的基础理论研究、关键技术研发和系统平台建设等方面系取得了丰富的研究成果。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul><li>强弱关系：紧密频繁或偶然</li><li>结构洞</li><li>嵌入性：在四边形ABCD中连接AC，反映了AC之间关系的可靠性</li><li>桥：AB间的唯一路径 -&gt; 捷径：去除AB连边会让他们距离增加2以上</li><li>社会资本：人们在社会（社会网络）结构中所处的位置给他们带来的资源<ul><li>契结资本：强连接，表达性行动，情感</li><li>工具资本：弱连接，工具性</li></ul></li><li>正关系和负关系</li><li>结构平衡（三者皆是敌人导致敌人的敌人仍是敌人）</li><li>网络影响力：依赖性，排他性，饱和性，介数</li><li>核心-外围结构</li><li>网络社区发现：节点要求，集合要求，互不重叠，层次化社区结构，如何提取隐藏的社区结构</li><li><strong>激活扩散理论</strong> ：一个概念被激活，其效应可以扩散到与其相关联的其他节点，<em>NLP相关</em></li><li>注意力网络：近因，首因，边际递减效应</li><li>流行语传播网络：信息模因（Meme）<ul><li>信息在人群中传播就像基因一样，会不断复制和演化</li><li>基于网络的群体情感行为演化</li></ul></li><li>网络中的同质现象：由节点主动选择（选择相似特征【或自己所喜欢的特征？】的朋友）和被动影响（成朋友之后的影响）交错而成</li><li>从众行为：信息效应，直接受益效应<ul><li>信息效应：根据有限的信息进行合理推理，和模仿顺从不同，“信息级联”</li><li>理性状态下的认知失衡</li></ul></li></ul><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><ul><li>动态网络</li><li>现有社交网络（推特、微博等数据集）中缺乏负关系（对抗敌对）的挖掘与应用</li><li>无向图中负号偶数是平衡，有向图中负号奇数是有效调节</li><li>同质性，“圈层”</li><li>激活扩散中，概念如何更高效准确的储存和调用（进化？）</li></ul><h2 id="课程研讨记录"><a href="#课程研讨记录" class="headerlink" title="课程研讨记录"></a>课程研讨记录</h2><p>班上同学的研讨和idea分享，待学习补充</p>]]></content>
      
      
      <categories>
          
          <category> 课程笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复杂网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention Is All You Need</title>
      <link href="/attention-is-all-you-need/"/>
      <url>/attention-is-all-you-need/</url>
      
        <content type="html"><![CDATA[<p>Transformer: 基于多头自注意力机制进行序列到序列的encoder-decoder架构，完全摒弃循环层和卷积层，nlp领域大山头！</p><h2 id="论文十问"><a href="#论文十问" class="headerlink" title="论文十问"></a>论文十问</h2><p>由 <a href="https://readpaper.com/"><em>ReadPaper平台</em></a> 提出，有助于总结信息，构建认知模型。</p><blockquote><ol><li>论文试图解决什么问题？<blockquote><p>在机器翻译、句法分析等nlp任务上取得好成绩，进行更准确的序列转化（编-解码）。出发点在于基于CNN、RNN的模型在长距离依赖下的限制，更好的进行并行计算。</p></blockquote></li><li>这是否是一个新的问题？<blockquote><p>不是新问题，但是是一个全新的思路。</p></blockquote></li><li>这篇文章要验证一个什么科学假设？<blockquote><p>在序列到序列学习中，用（多头）自注意力机制替代循环层、卷积层，可以取得很好的结果。</p></blockquote></li><li>有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？<blockquote><p>暂略</p></blockquote></li><li>论文中提到的解决方案之关键是什么？<blockquote><p>用（多头）自注意力机制完全替代循环层和卷积层、位置编码、适当位置加入前馈神经网络、注意力机制的多层灵活运用。</p></blockquote></li><li>论文中的实验是如何设计的？<blockquote><p>在公开数据集上训练，和其他模型作比较，并控制变量评估了模型中各个部分所带来的精度影响。</p></blockquote></li><li>用于定量评估的数据集是什么？代码有没有开源？<blockquote><p>WMT 2014 English-German dataset，WMT 2014 English-French dataset，Wall Street Journal (WSJ) portion of the Penn Treebank（宾州树库），已经在 <a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a> 上开源模型。</p></blockquote></li><li>论文中的实验及结果有没有很好地支持需要验证的科学假设？<blockquote><p>实验结果相当乐观，在机器翻译和句法分析等nlp任务上取得了截止论文发表时最高的评分。</p></blockquote></li><li>这篇论文到底有什么贡献？<blockquote><p>提出了一套革命式的nlp研究框架。</p></blockquote></li><li>下一步呢？有什么工作可以继续深入？<blockquote><p>扩展到其他领域（音视频图像，以及其他类型的序列到序列学习领域），模型变种（基本被卷王们做完了）。</p></blockquote></li></ol></blockquote><p>还可以点击这里参考<a href="https://readpaper.com/paper/2963403868/questions-detail?questionId=534901540122656768">公开回答</a></p><h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p>待绘制添加</p><table><thead><tr><th><img src="tianyi.jpg" width="30%"></th></tr></thead><tbody><tr><td><center>可爱小天依镇楼</center></td></tr></tbody></table><table><thead><tr><th><img src="1.jpg" width="300/"></th></tr></thead><tbody><tr><td><center>模型框架图</center></td></tr></tbody></table><table><thead><tr><th><img src="2.jpg" width="300/"></th><th><img src="3.jpg" width="300/"></th></tr></thead><tbody><tr><td><center>注意力模型</center></td><td><center>参数影响测试</center></td></tr></tbody></table><h2 id="文章共读"><a href="#文章共读" class="headerlink" title="文章共读"></a>文章共读</h2><p><a href="attention.pdf">注意力机制参考资料</a><br>暂待补充</p><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><ol><li>自注意力机制(Q,K,V结构)本质是向量信息的交叉（交互）？是否流于形式，可以简化吗？可以拓展吗？<br>$ Q K^T = X W_q W_k^T X^T $, 其中 $ X = [X_1;X_2;…X_n] $…</li><li>positional encodings直接和word embeddings做和，是否不妥，实际含义为何？（词本身的含义与位置相关？如果用依存句法分析树来编码？），用向量拼接的方式怎么样（存在维数控制问题？）</li></ol><h2 id="原文-amp-个人标注"><a href="#原文-amp-个人标注" class="headerlink" title="原文 &amp; 个人标注"></a>原文 &amp; 个人标注</h2><p><a href="1.pdf">PDF下载链接</a></p><div class="row">    <embed src="1.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="外文写作"><a href="#外文写作" class="headerlink" title="外文写作"></a>外文写作</h2><h3 id="用词"><a href="#用词" class="headerlink" title="用词"></a>用词</h3><table><thead><tr><th align="left">词语</th><th align="left">文中释义</th><th align="left">词语</th><th align="left">文中释义</th></tr></thead><tbody><tr><td align="left">auto-regressive</td><td align="left">自动回归的</td><td align="left">albeit</td><td align="left">尽管</td></tr><tr><td align="left">stacked</td><td align="left">堆叠的</td><td align="left">residual connection</td><td align="left">残差连接</td></tr><tr><td align="left">parallel</td><td align="left">并行</td><td align="left">simultaneously</td><td align="left">同时</td></tr><tr><td align="left">additive attention</td><td align="left">累积注意力</td><td align="left">compatibility function</td><td align="left">兼容函数</td></tr><tr><td align="left">in magnitude</td><td align="left">在规模上</td><td align="left">concatenate</td><td align="left">连接</td></tr><tr><td align="left">mimics</td><td align="left">模仿</td><td align="left">hypothesize</td><td align="left">假定</td></tr><tr><td align="left">extrapolate to</td><td align="left">外推到</td><td align="left">interpretable</td><td align="left">可解释的</td></tr><tr><td align="left">training regime</td><td align="left">训练机制</td><td align="left"></td><td align="left"></td></tr></tbody></table><h3 id="用句"><a href="#用句" class="headerlink" title="用句"></a>用句</h3><blockquote><ul><li>left and right halves of Figure 1<blockquote><p>图一的左右半部分</p></blockquote></li><li>as depicted in Figure 2.<blockquote><p>如图二所示</p></blockquote></li></ul></blockquote><h2 id="复现-amp-运用技巧"><a href="#复现-amp-运用技巧" class="headerlink" title="复现 &amp; 运用技巧"></a>复现 &amp; 运用技巧</h2><p>暂待</p>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> Self-Attention </tag>
            
            <tag> Mask </tag>
            
            <tag> Multi-Head Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>这是<em>网站</em>搭建后<strong>第一篇</strong>测试博客！<code>欢迎</code>来到我的个人网站！</p><p><em><strong>源码</strong></em> 放在<a href="https://github.com/BillZid">github主页</a>上。</p><blockquote><p><del>求你看看</del></p><blockquote><p>多多交流！</p></blockquote></blockquote><hr><h2 id="插入代码"><a href="#插入代码" class="headerlink" title="插入代码"></a>插入代码</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">hello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hello World!"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>还可以<code>print("Hello again!")</code></p><h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><center><img src="01.jpg" width="30%" height="30%"><p>可爱小天依</p></center><h2 id="插入pdf"><a href="#插入pdf" class="headerlink" title="插入pdf"></a>插入pdf</h2><div class="row">    <embed src="1.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="插入表格"><a href="#插入表格" class="headerlink" title="插入表格"></a>插入表格</h2><table><thead><tr><th align="left">001</th><th align="left">002</th><th align="left">003</th></tr></thead><tbody><tr><td align="left">数学</td><td align="left">计算机</td><td align="left">管科</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 随笔记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网站测试 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
