<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>就业分享会-2022-11</title>
      <link href="/jiu-ye-fen-xiang-hui-2022-11/"/>
      <url>/jiu-ye-fen-xiang-hui-2022-11/</url>
      
        <content type="html"><![CDATA[<h1 id="会议主题：院所联合就业经验分享会"><a href="#会议主题：院所联合就业经验分享会" class="headerlink" title="会议主题：院所联合就业经验分享会"></a>会议主题：院所联合就业经验分享会</h1><p>参考微信推文<a href="https://mp.weixin.qq.com/s/5blo8NWl92cSQU1-mRRpxg">预告|院所联合就业经验分享会–管理学领域专场</a></p><p>腾讯会议号：424 6669 1978</p><h2 id="1-吴锦伟"><a href="#1-吴锦伟" class="headerlink" title="1. 吴锦伟"></a>1. 吴锦伟</h2><p><strong>姓名</strong>： 吴锦伟</p><p><strong>专业</strong>：创新管理</p><p><strong>毕业院系</strong>：中丹学院  </p><p><strong>毕业年份</strong>：2019年</p><p><strong>毕业去向</strong>：京东集团TET13管理培训生（金融方向）</p><p><strong>工作经历（历任）</strong>：</p><p>金融算法工程师：股票&amp;基金&amp;债券，利率衍生品&amp;信用衍生品（CRMW）量化分析等；</p><p>风控策略分析师：现金贷点中额度定价管控，客群识别、金条子账户（独立产品）分析等。</p><p><strong>分享内容</strong>：</p><p>（1）求职定位：如何找到适合自己的工作</p><p>（2）工作内容：金融算法工程师/风控策略分析师的具体工作内容</p><p>（3）职场感悟：一道追求专业性、匹配性、唯一性、及时性的多目标求解问题</p><p><strong>分享笔记</strong>：</p><p>京东管培 专业没限制 证书没限制</p><p>券商实习看公众号，会有人招继任，大部分不会放在官网上</p><p><strong>微信</strong>：Jennings0</p><h2 id="2-钱家彦"><a href="#2-钱家彦" class="headerlink" title="2. 钱家彦"></a>2. 钱家彦</h2><p><strong>姓名</strong>：钱家彦</p><p><strong>专业</strong>：金融学</p><p><strong>毕业院系</strong>：经济与管理学院</p><p><strong>毕业年份</strong>：2021年</p><p><strong>曾获荣誉</strong>：北京市优秀毕业生、中国科学院大学三好学生、优秀团干部</p><p><strong>实习经历</strong>：招商局资本、中债登、罗兰贝格、海通证券、申万宏源证券、安永等</p><p><strong>毕业去向</strong>：中国光大银行总行智能风控中心</p><p><strong>工作内容</strong>：金融市场相关特征加工，策略设计，项目管理等。</p><p><strong>分享内容</strong>：</p><p>（1）秋招经验分享</p><p>（2）在校生能为未来做什么准备</p><p><strong>分享笔记</strong>：</p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112234925397-1668268193260-5.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235119510.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235129498.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235137901-1668268298938-7.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235148007.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235200450.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235207274.png"></p><p>PE/vc</p><p>银行管培不分专业，理工科也可以，金融基础需要的不多，甚至还有优势</p><p>进了银行会培训，基础知识还好</p><p><strong>微信</strong>SkyDebora</p><h2 id="3-孙琬莹"><a href="#3-孙琬莹" class="headerlink" title="3. 孙琬莹"></a>3. 孙琬莹</h2><p><strong>姓名</strong>：孙琬莹 </p><p><strong>专业</strong>：管理科学与工程</p><p><strong>毕业院系</strong>：公管学院</p><p><strong>毕业年份</strong>：2022年</p><p><strong>毕业去向</strong>：歌尔股份战略与投资部</p><p><strong>工作内容</strong>：战投相关行业研究，公司战略规划的制定，组织和参与业务线产品线战略研讨等</p><p><strong>分享内容</strong>：</p><p>（1）招聘阶段：in-house战略、咨询、券商要如何入行，所需素质及如何选择offer</p><p>（2）工作阶段：公司战略部、投资部具体工作内容</p><p><strong>分享笔记</strong></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235220741.png"></p><p>面试什么，要给证据，举例子，学习能力强是怎么个强法。</p><p>感受不到压力是和权力一点关系都没有</p><p><strong>微信</strong>：swy295</p><h2 id="4-熊丽彬"><a href="#4-熊丽彬" class="headerlink" title="4. 熊丽彬"></a>4. 熊丽彬</h2><p><strong>姓名</strong>：熊丽彬</p><p><strong>专业</strong>：管理科学与工程</p><p><strong>毕业院系</strong>：公管学院</p><p><strong>毕业年份</strong>：2021年</p><p><strong>毕业季offer情况</strong>：</p><p>华夏幸福投资岗</p><p>伊利战略管培</p><p>北汽投资规划岗</p><p>滴滴战略分析</p><p>字节战略分析</p><p>美团策略分析</p><p><strong>毕业去向</strong>：滴滴出行科技有限公司</p><p><strong>工作内容</strong>：作为战略bp制定BP部门年度战略规划和目标拆解，同时负责网约车下一业务线的定价策略</p><p><strong>分享内容</strong>：</p><p>（1）如何选择就业方向</p><p>（2）如何平衡秋招季的心态</p><p>（3）如何为自己的方向准备</p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235231654.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235237490.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235250829.png"></p><p><strong>电话</strong>：18180405627</p><p><strong>微信</strong>：Bin839550874</p><h2 id="5-庄立"><a href="#5-庄立" class="headerlink" title="5. 庄立"></a>5. 庄立</h2><p><strong>姓名</strong>：庄立</p><p><strong>专业</strong>：行政管理</p><p><strong>毕业院系</strong>：公管学院</p><p><strong>毕业年份</strong>：2021年</p><p><strong>毕业季offer情况</strong>：</p><p>国企管理岗</p><p>事业单位管理岗</p><p><strong>毕业去向</strong>：</p><p>原工作单位：中国新闻社党委办公室</p><p>现工作单位：中宣部国际传播局（借调）</p><p><strong>工作内容</strong>：</p><p>原单位：文稿起草；党的学习宣传工作；其他办文办件等日常工作。</p><p>现单位：文稿起草；联系对接央媒及地方媒体开展国传工作；其他办文办件等日常工作。</p><p><strong>分享内容</strong>：</p><p>（1）笔试面试心得</p><p>（2）工作经历分享</p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235303943.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235308797.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235316221.png"></p><p><img src="/jiu-ye-fen-xiang-hui-2022-11/image-20221112235322535.png"></p><h2 id="会议记录"><a href="#会议记录" class="headerlink" title="会议记录"></a>会议记录</h2><blockquote><p>2022/11/12</p><p>中丹胡永佳 18:33<br>可以听到</p><p>ABC 18:58<br>师兄可以介绍下几段实习经历吗？找相关金融实习需要匹配的技能有哪些</p><p>Yu章鱼喵 19:00<br>请问简历通过初筛到通知面试大概要多久呢？有没有说初筛通过了之后就石沉大海了？投简历到拿到offer每个环节都有可能被筛掉吗？谢谢师兄</p><p>ツキの月 19:06<br>请问师兄 互联网公司比如像京东这种 会看本科学校吗（本科不是985，第一轮简历就被筛掉这种情况）</p><p>Yu章鱼喵 19:06<br>好的，非常感谢！</p><p>Renee 19:07<br>学长您好，想问一下非应届生找日常实习，尤其是券商的实习主要是通过官网投递么？有没有什么其他的信息渠道呢？另外能重新放一下您微信号的PPT么，抱歉刚才没记下来</p><p>刘林林 19:07<br>回答完以上问题，问答环节就结束啦~</p><p>RandyOrton 19:10<br>券商实习看公众号，会有人招继任，大部分不会放在官网上</p><p>1736599 19:22<br>果壳论坛 怎么才能注册成功 各位</p><p>听那冷雨 19:47<br>师姐，三线城市是选四大行这类大银行的二级分行岗，还是地方的城商行好呢？非金融专业，打算去银行科技岗之类的，但担心城商行也不一定能进总行</p><p>q 19:47<br>请问师姐，理工科去银行能做什么吗？您周围有没有案例可以分享吗？</p><p>孙琬莹撤回了一条消息</p><p>听那冷雨 19:48<br>hang</p><p>孙琬莹撤回了一条消息</p><p>Yu章鱼喵 19:49<br>请问海投的话，遇到笔试面试时间冲突怎么办呢？</p><p>shan 19:50<br>请问 物理专业的适合 去银行吗? 会因为专业不符合 直接简历或者面试 没机会吗？</p><p>q 19:53<br>那理工科需要具备哪些能力才能有优势呢？</p><p>RandyOrton 19:54<br>想做pe，纯金融背景怎么突出自己相对于理工科背景的优势？</p><p>ABC 19:54<br>理工科想要进银行，金融基础知识需要具有吗</p><p>ツキの月 19:55<br>想听听师姐对ppt上的问题的解读</p><p>刘林林 19:57<br>回答完以上问题，问答环节就结束啦~</p><p>ABC 19:57<br>请问师姐，博士段筛选也看本科吗</p><p>ww 19:57<br>师姐 理学博士进银行适合什么岗位呢？除了建模算法之类的</p><p>uu 20:01<br>请问师姐可以简短讲一下ppt上这三个常见困惑嘛</p><p>刘林林 20:01<br>回答完以上问题，问答环节就结束啦~</p><p>旁听 20:38<br>请问师姐，一段实习实习多久好？</p><p>serena撤回了一条消息</p><p>旁听 20:39<br>一定要待够三个月吗</p><p>q 20:39<br>请问师姐，部门的内部斗争指什么呢？如果您入职之后遇到这个问题该怎么办呢？</p><p>serena 20:40<br>师姐 请问战略岗对python C++有硬性要求嘛，纯文科可以进吗</p><p>Dory.撤回了一条消息</p><p>ABC 20:41<br>师姐刚刚说21年春季开始实习，当时时间安排是怎么样子的？</p><p>Kayla 20:43<br>师姐想问一下你当时实习和科研是怎么平衡的呢？是前期专注实习，到最后才开始处理论文吗？这样会不会很难</p><p>Kayla 20:44<br>好的 谢谢师姐</p><p>寇鑫淼 20:45<br>如何提升英语请问师姐</p><p>WIM 20:45<br>科学上网了呀</p><p>旁听 20:59<br>请问师姐是如何学习派森的</p><p>卢嘉悦 20:59<br>学姐，想请教下您觉得战略岗的核心技能是什么？</p><p>郑文欣 21:01<br>因为两位师姐都提到自己秋招“失败”，想知道除了因为自己没有做好准备，会不会还因为管理学专业的就业前景不好呢？方便知道师姐身边的同学大多是去什么岗位的吗？</p><p>杨凡 21:03<br>请问师姐是如何在科研和实习之间做选择的呢？我们应该如何判断自己更适合从事科研，还是进入企业呢？</p><p>吴易然 21:06<br>师姐，哪些因素会不利于考博成功呢？谢谢师姐的经验</p><p>刘怡伶 21:06<br>请问师姐学生干部经历对于进入这些战略岗、运营岗重要吗</p><p>杨凡 21:06<br>谢谢师姐的分享！</p><p>吴易然 21:06<br>好的师姐</p><p>shan 21:07<br>怎么看待 第一份工作 有无北京户口的问题？ （如果就想在北京发展的话），感觉 户口 平台 待遇 三者 不兼得</p><p>刘怡伶 21:07<br>谢谢师姐～</p><p>WIM 21:08<br>航天 有户口、大平台、待遇也好</p><p>serena 21:08<br>师姐方便放一下联系方式吗</p><p>郑文欣 21:09<br>谢谢师姐</p><p>熊丽彬 21:09<br>18180405627</p><p>ABC 21:09<br>请问下师姐说的五个院校是什么呀？</p><p>serena 21:09<br>谢谢师姐</p><p>熊丽彬 21:09<br>Bin839550874</p><p>旁听 21:12<br>这个国科大祖传ppt模板哈哈哈</p><p>小崔 21:16<br>打球时打开了我的嘴</p><p>吴易然 21:18<br>师兄好，文科生进了大学后没学过数学，对于行测很多题目陌生，不会解答怎办？谢谢师兄</p><p>听那冷雨撤回了一条消息</p><p>默认昵称 21:28<br>请问师兄方便说下有参加了哪些省市的选调嘛？谢谢师兄</p><p>郑文欣 21:28<br>请问师兄建议在硕士期间去报名考试练练手吗？</p><p>彭宇 21:29<br>可以请问下师兄的同学都是找的什么样的岗位呢？(感觉这个世界不需要纯纯文科生[表情]</p><p>吴易然 21:29<br>谢谢师兄</p><p>WIM 21:30<br>理论上只有应届生能考</p><p>郑文欣 21:31<br>谢谢师兄</p><p>WIM 21:31<br>北京公务员和长三角、珠三角 相比 性价比？</p><p>彭宇 21:32<br>谢谢师兄～高低有条出路</p><p>肖娅 21:32<br>师兄可以留个联系方式吗</p><p>q 21:32<br>师兄现在的工作能介绍一下吗？！</p><p>q 21:33<br>借调有机会留在那边吗？为什么要去借调呢？</p><p>庄立 21:35<br>微信：13161417040</p><p>旁听 21:50<br>在听</p><p>吴易然 21:50<br>师兄讲得很有启发</p><p>Kayla 21:50<br>轮岗是轮哪个岗位啊</p><p>q 21:51<br>职能线和业务线的区别是什么呢，这两个发现前景怎么看？</p><p>ABC 21:51<br>请问，中国远洋会卡本科吗</p><p>肖娅 21:51<br>请问师兄，央企在简历筛选和面试环节分别最看重什么方面？</p><p>高金来 21:51<br>请问类似央企管培生这种工作的节奏怎么样的</p><p>旁听 21:51<br>学长目前的具体岗位是什么</p><p>uu 21:52<br>师兄Offer是11月到春节前密集收到的么（＆看到师兄offer的行业岗位都有很大差异）</p><p>q 21:52<br>您轮岗了几个部门呢？感觉怎么样？</p><p>zp 21:52<br>想问师兄，央企是如何选拔的</p><p>Lucas 21:53<br>中海运的管培会看重些行业公司的实习经历呢</p><p>uu 21:54<br>物流行业前景如何 央国企（远洋海运）与私企（京东物流/菜鸟/顺丰）未来发展方向会差很多么</p><p>庄立 21:57<br>辛苦了</p><p>q 21:57<br>谢谢各位师兄师姐的分享！</p><p>默认昵称 21:57<br>谢谢各位师兄师姐</p><p>默认昵称 21:57<br>辛苦啦</p><p>李子嘉 21:57<br>感谢</p><p>旁听 21:57<br>感谢！</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 会议纪要 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 就业 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模式识别与机器学习</title>
      <link href="/mo-shi-shi-bie-yu-ji-qi-xue-xi/"/>
      <url>/mo-shi-shi-bie-yu-ji-qi-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="贝叶斯推断"><a href="#贝叶斯推断" class="headerlink" title="贝叶斯推断"></a>贝叶斯推断</h2><ul><li>贝叶斯 诊断推断</li><li>贝叶斯没有真正建模因果，建模的是相关</li><li>可解释性和稳定性</li><li>狗在草地上，结果分类狗建模成了草地</li></ul><h2 id="无监督学习-降维"><a href="#无监督学习-降维" class="headerlink" title="无监督学习-降维"></a>无监督学习-降维</h2><ul><li><p>维数灾难：随着空间维度的增长，数据点越来越分散，以至于距离和密度的概念越来越模糊，没有一种距离函数或相似性函数能避免高维带来的问题<img src="/mo-shi-shi-bie-yu-ji-qi-xue-xi/image-20221114133916187.png"></p></li><li><p>算法用到距离时，就会受到影响</p></li><li><p>基本假设：维数可以被压缩，有些维数是无效的</p></li><li><p>方法：维度选择 维度抽取   即做映射</p></li><li><p>采样，Johnson-Lindestrauss (JL) embedding lemma</p></li><li><p>手工移除特征：冗余的，不相关的，质量差的特征</p></li><li><p>矩阵和矩阵乘法本质上是在做线性变换</p></li><li><p>矩阵分解是将一个矩阵分解为几个矩阵的乘法：高维矩阵的低秩近似</p><p>方阵-特征分解（对角化），非方阵-奇异值分解（SVD)</p><p><img src="/mo-shi-shi-bie-yu-ji-qi-xue-xi/%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89.png"></p></li><li><p>MDS算法：由距离矩阵构造一个低维空间</p></li><li><p>PCA降维 &amp; kerner PCA</p></li><li><p>流形学习</p></li><li></li></ul><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><ul><li>因果+神经网络</li><li>对偶问题:转换数据量与数据维度,可不可以综合</li></ul>]]></content>
      
      
      <categories>
          
          <category> 课堂笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率和统计</title>
      <link href="/gai-lu-he-tong-ji/"/>
      <url>/gai-lu-he-tong-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="概率分布表"><a href="#概率分布表" class="headerlink" title="概率分布表"></a>概率分布表</h2><img src="概率分布表1.jpg" width="70%"><img src="概率分布表2.jpg" width="70%"><img src="概率分布表3.jpg" width="70%"><img src="概率分布表4.jpg" width="70%"><h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><ul><li>泊松分布 二项分布 指数分布<ul><li>二项分布是抛n次硬币中取头像面（概率为p）的次数，泊松分布看成二项分布的极限，取n*p为极限作为事件发生的概率，事件发生次数的分布。二项分布可以看成事件之间间隔时间的分布。</li><li>n个独立柏松变量的和仍服从泊松分布，且参数$\lambda$为他们参数的和，用特征函数性质容易验证。</li></ul></li><li>特征函数常用性质如下:<br>(1) $\varphi(0)=1, \varphi(t) \leq \varphi(0), \varphi(-t)=\bar{\varphi}(t)$<br>(2) 若 $Y=a X+b$ ，则:<br>$$<br>\varphi_Y(t)=e^{j b t} \varphi_X(a t)<br>$$<br>(3) 若 $X$ 与 $Y$ 相互独立，且 $Z=X+Y$ ，则:<br>$$<br>\varphi_Z(t)=\varphi_X(t) \varphi_Y(t)<br>$$<br>(4) 若随机变量 $X$ 具有 $n$ 阶矩，则其特征函数 $n$ 阶可导，且当 $0 \leq k \leq n$ 时，有:<br>$$<br>\varphi^{(k)}(0)=j^k E X^k<br>$$<br>此条性质可用于求解随机变量的各阶矩(若存在)，有时可以避免进行复杂的无穷积分。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 自学笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>seq2seq</title>
      <link href="/seq2seq/"/>
      <url>/seq2seq/</url>
      
        <content type="html"><![CDATA[<h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p><a href="seq2seq.xmind">思维导图下载链接</a></p><p><img src="/seq2seq/seq2seq.png" alt="思维导图"></p><h2 id="原文-amp-个人批注"><a href="#原文-amp-个人批注" class="headerlink" title="原文 &amp; 个人批注"></a>原文 &amp; 个人批注</h2><p><a href="seq2seq.pdf">pdf下载链接</a></p><div class="row">    <embed src="seq2seq.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><p>暂略</p>]]></content>
      
      
      <categories>
          
          <category> 论文粗读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 2014-09 </tag>
            
            <tag> seq2seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>杂文书摘01</title>
      <link href="/za-wen-shu-zhai-01/"/>
      <url>/za-wen-shu-zhai-01/</url>
      
        <content type="html"><![CDATA[<blockquote><p>共计：4本书·44篇书摘<br>日期：2022年11月06日</p></blockquote><h2 id="《洛丽塔-弗拉基米尔·纳博科夫-》"><a href="#《洛丽塔-弗拉基米尔·纳博科夫-》" class="headerlink" title="《洛丽塔 (弗拉基米尔·纳博科夫)》"></a>《洛丽塔 (弗拉基米尔·纳博科夫)》</h2><blockquote><p>洛丽塔是一本以恋童犯视角为基础的小说，但是，请不要看任何书都代入主角视角！作者的文学创作，恰恰让我们看到，主角是怎么把自己的变态、欺骗、掌控和欲望修饰成他眼中的爱的。</p></blockquote><ul><li><p>“你知道，死最可怕的地方就是你完全得靠你自己。” 我还有其他一些一直受到抑制的回忆，现在它们都自行展开，成为没有四肢的痛苦的怪物。 如今她只是那个性感少女以淡淡的紫罗兰清香和枯萎的树叶的形态所表现出的回声；</p></li><li><p>确实，未成年的少女所以对我具有魅力，也许并不怎么在于她们纯洁、幼小、不得接近的小仙 女似的美貌有多清明澄澈，而在于那种情况的安全性，因为在那种情况下，无限的完美填补了 极少的赐予和极多的许诺之间的空白——那许多永远也得不到的灰色玫瑰。</p><blockquote><p>原文摘录，不代表个人观点</p></blockquote></li><li><p>正因为这个幻象可望而不可及，又不可能凭借知道一个附带的禁忌而去对它加以破坏，所以在这个火热的幻影中有一种无上的完美，它使我心头狂热的喜悦之情也变得完美无缺。</p></li><li><p>她那么善良，里塔，是那么个随和开朗的人，因此我想仅仅出于友好和同情，她就会把自己献给任何一个可怜的生灵或感伤的谬误，比如一棵折断的老树或一只失去配偶的豪猪。</p></li><li><p>不论我对她的爱受到什么影响，我那该受诅咒的本性却难以改变。 谁能说出我们这么中断嬉戏会叫一条小狗心里有多伤感？</p></li><li><p>几乎没有什么比一般女大学生的松垮笨重的骨盆、粗壮的小腿和惨淡的肤色叫我感到更为厌恶的体形了（大概因为我在她们身上看到了粗糙的女性肉体的棺木，而我的性感少女就给活埋在里面）；</p><blockquote><p>原文摘录，不代表个人观点</p></blockquote></li></ul><h2 id="《为什么男生分手后很快就释怀了-，女生则需要很久很久？-zhihu-com-》"><a href="#《为什么男生分手后很快就释怀了-，女生则需要很久很久？-zhihu-com-》" class="headerlink" title="《为什么男生分手后很快就释怀了 ，女生则需要很久很久？ (zhihu.com)》"></a>《为什么男生分手后很快就释怀了 ，女生则需要很久很久？ (zhihu.com)》</h2><ul><li><p>而且爱情对于人生幸福的占比，只有20%。 亲情占比20%，社交圈占比30%，爱好占比20%，成就占比10%。 所以哪怕失去了感情，他们依旧有80%的精彩内容，能够支撑自己的生活，使得他们在思想依赖上，可以更加独立，他们是向前走的，他们清楚应该拥有更好的生活。 很明显的，在感情中偏向于事态性心理，和加分制发展的女生，对于思想，安全感，幸福感的依赖要大于男生。</p><blockquote><p>原文摘录，不代表个人观点，先问是不是，再问为什么，作者的观点仅代表他个人总结出来的经验，性别没有高下之分。</p></blockquote></li><li><p>只有成熟的人才拥有给予爱的能力，也更能体谅对方的需求，他们的付从来就不比任何人少， 而面临感情问题，他们又可以很快的释怀，振作起来。 就是因为他们是一个完整的个体。 他们拥有自己给予自己幸福的能力。 安全感，幸福感，认同感，归属感，默契感，都会通过自我的丰富去争取和创造，这是一个足 够成熟，足够上进，足够积极的两性思维。</p></li></ul><h2 id="《有哪些是你进了体制内才知道的事情-zhihu-com-》"><a href="#《有哪些是你进了体制内才知道的事情-zhihu-com-》" class="headerlink" title="《有哪些是你进了体制内才知道的事情? (zhihu.com)》"></a>《有哪些是你进了体制内才知道的事情? (zhihu.com)》</h2><ul><li>有位朋友说得很好，在词字上如此的揣摩，是不人道的，是反人性的。 因为人性向往真实的成就，自己骗不了自己，写辣鸡就是反人性，无可辩驳。</li></ul><h2 id="《剑来1-9-烽火戏诸侯-》"><a href="#《剑来1-9-烽火戏诸侯-》" class="headerlink" title="《剑来1-9 (烽火戏诸侯)》"></a>《剑来1-9 (烽火戏诸侯)》</h2><blockquote><p>（网络小说，仅认可句子写得好，不代表认可观点）</p></blockquote><ul><li><p>“好林泉都付与闲人，好娘们都被拐走了。” 读书识字，心肝都被墨汁浸透，心肝肚肠都黑得很。 怎么办呢，也不能不喜欢他，也舍不得他不喜欢自己啊。 这些情愁，未下眉头，又上心头。</p></li><li><p>谁可奉饶天下先</p></li><li><p>与同龄人元宝关系再好，但是双方都是纯粹武夫，较劲肯定会有，女子往往如此，哪怕再好的关系，也会在可爱眉眼间、嫣然笑容里偷藏着小小的较劲，这些只是人之常情，比那男人的争强斗胜，其实更加婉约动人。</p></li><li><p>“夸人内秀，其实就骂人长得丑。” </p></li><li><p>宁姚坐在陈平安身边，转头瞪着左右，埋怨道：“大过年的！” 左右憋了半天，点头道：“以后注意。” 陈平安偷着乐呵。</p></li><li><p>一位好姑娘不喜欢你，一定是你还不够好，等到你哪天觉得自己足够好了，姑娘兴许也嫁了人，然后连她的孩子都可以出门打酒了，在路上见着了你陈三秋，喊你陈叔叔，那会儿，也别伤 心，是缘份错了，不是你喜欢错了人，记住，在那位姑娘嫁人之后，就别纠缠不清了，把那份 喜欢藏好，都放在酒里。每次喝酒的时候，念着点她把未来日子过得好，别总想着什么她日子 过不好，回心转意来找你，那才是一个男人，真正的喜欢一个姑娘。</p></li><li><p>对天地怀有敬畏之心，将自己视为生死大敌。”</p></li><li><p>他们一起仰头望去，小巷狭窄，好像天大地大，只有一条线的光亮和出路。 但是毕竟那条光线，就在两位少年的头顶，并且被他们看到了。</p></li><li><p>世间人与事，理解那些脉络，不意味着认同。 为了有朝一日，我可以不用在小事上斤斤计较，</p></li><li><p>大是大非寸步不让，就足够了，小事上与心爱女子掰扯道理作甚？你是娶了个媳妇进门，还是当教书先生收了个弟子啊。</p></li><li><p>“陈平安，赤子之心，不是一味单纯，把复杂的世道，想得很简单。而是你知道了很多很多， 世事，人情，规矩，道理。最终你还是愿意坚持当个好人，哪怕亲身经历了很多，突然觉得好 人好像没好报，可你还是会默默告诉自己，愿意承受这份后果，坏人混得再好，那也是坏人， 那终究是不对的。”</p></li><li><p>我们每天说什么话，做什么事，真的就只是几句话几件事吗？不是的，这些言语和事情，一条 条线，聚拢在一起，就像西边大山里边的溪涧，最后变成了龙须河，铁符江。这条江河，就像 是我们每个人最根本的立身之本，是一条藏在我们心里边的主要脉络，会决定了我们人生最大 的悲欢离合，喜怒哀乐。</p></li><li><p>不解，陈先生不就是睡觉有些呼噜声嘛，马姑娘 世间的事情，其实对错分明，千万别觉得人心复杂，就连最基本的是非都混淆了，</p></li><li><p>有句家乡俗语，瓦罐不离井口破，将军难免阵上亡。投身行伍，沙场争锋，就等于将脑袋拴在 裤腰带上了。</p></li><li><p>男子让着些女子，强者让着些弱者，同时又不是那种居高临下的施舍姿态，可不就是天经地义 的事情吗？</p></li><li><p>世人对于强者，既厌恶，又崇拜。 这就是人性的根本之一。 知错能改善莫大焉。 原来真正难处不在改，而是在知。</p></li><li><p>“遇上对错之分的时候，当一个人置身事外，不少人会不问是非，而一味偏袒弱者，对于强者 先天不喜，无比希望他们跌落神坛，甚至还会苛责好人，无比希望一个道德圣人出现瑕疵，同时对于恶人的偶尔善举，无比推崇，道理其实不复杂，这是我们在争那个小的‘一’，尽量均衡，不让一小撮人占据太多，这与善恶关系都已经不大了。</p></li><li><p>世事人情，是不是一个人想得越深，就越与人无话可说？</p></li><li><p>欠一些人情，并不可怕，有借有还，将来朋友遇上了难事，才能更轻松些开口，只要别好借难 还就是了。</p></li><li><p>不听不听王八念经，老王八念经最难听。</p></li><li><p>立场可以有，也很难没有，但是不意味着‘只’讲自己的立场，就可以万事不顾，那种问心无 愧，是狭隘的。学问也好，为人也好，最根本的立身之本，是相通的，贤人君子圣人相通，老百姓和帝王将相、练气士相通。</p></li><li><p>什么我们讲立场、不问是非，就错了？知道为什么吗？”</p></li><li><p>陈平安能够对顾璨感同身受，那只是因为陈平安走了更远的道路，顾璨却没有，对于他来说， 家乡泥瓶巷，再到书简湖，就是整个江湖和天下了。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 书摘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂文书摘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>被讨厌的勇气-书摘</title>
      <link href="/bei-tao-yan-de-yong-qi-shu-zhai/"/>
      <url>/bei-tao-yan-de-yong-qi-shu-zhai/</url>
      
        <content type="html"><![CDATA[<img src="cover.jpg" width="70%"><blockquote><p>共计：1本书·105篇书摘<br>日期：2022年11月06日</p></blockquote><p>感兴趣可以深入阅读原文: <a href="https://pan.baidu.com/s/1Jp-lQPon3w9S2SXkj9MENA?pwd=bill">pdf &amp; epub</a></p><h2 id="《被讨厌的勇气：“自我启发之父”阿德勒的哲学课-岸见一郎，古贺史健-》"><a href="#《被讨厌的勇气：“自我启发之父”阿德勒的哲学课-岸见一郎，古贺史健-》" class="headerlink" title="《被讨厌的勇气：“自我启发之父”阿德勒的哲学课 (岸见一郎，古贺史健) 》"></a>《被讨厌的勇气：“自我启发之父”阿德勒的哲学课 (岸见一郎，古贺史健) 》</h2><br><ul><li><p>因为表扬是有能力的人对没能力的人所作出的评价。 只要能够对所有人都建立起虽不同但平等的横向关系，那就根本不会产生自卑情结。</p></li><li><p>希望被别人表扬或者反过来想要去表扬别人，这是一种把一切人际关系都理解为纵向关系的证明。你也是因为生活在纵向关系中，所以才希望得到表扬。阿德勒心理学反对一切纵向关系，提倡把所有的人际关系都看作横向关系。在某种意义上，这可以说是阿德勒心理学的基本原理。</p></li><li><p>人表扬他人的目的就在于操纵比自己能力低的对方，其中既没有感谢也没有尊敬。</p></li><li><p>如果是因为你的反对就能崩塌的关系，那么这种关系从一开始就没有必要缔结，由自己主动舍弃也无所谓。活在害怕关系破裂的恐惧之中，那是为他人而活的一种不自由的生活方式。</p></li><li><p>这里有需要记住的行动原则。当我们在人际关系中遇到困难或者看不到出口的时候，首先应该考虑的是 <strong>倾听更大共同体的声音</strong> 这一原则。</p></li><li><p>的确，宇宙很难立刻想象出来。但是，希望你不要只拘泥于眼前的共同体，而要意识到自己还属于别的共同体，属于更大的共同体，例如国家或地域社会等，而且在哪里都可以作出某些贡献。</p></li><li><p>但是，这只不过是从公司这个小的共同体中被分离出来而己，任何人都还属于别的共同体。因为，无论怎样，我们的一切都属于地球这个共同体，属于宇宙这个共同体。</p></li><li><p>说只有付出了才能够找到自己的位置</p></li><li><p>就是直面 <strong>人生课题</strong> 。也就是不回避工作、交友、爱之类的人际关系课题，要积极主动地去面对。如果你认为自己就是世界的中心，那就丝毫不会主动融入共同体中，因为一切他人都是 <strong>为我服务的人</strong> ，根本没必要由自己采取行动。</p></li><li><p>阿德勒心理学认为归属感不是仅仅靠在那里就可以得到的，它必须靠积极地参与到共同体中去才能够得到。</p></li><li><p>哲人：只关心自己的人往往认为自己位于世界的中心。对于这样的人来说，他人只是“为我服务的人”；他们甚至会认为：“大家都应该为我服务，应该优先考虑我的心情。”<br>青年：就像王子或公主一样。<br>哲人：是的，正是如此。他们超越了“人生的主人公”，进而越位到“世界的主人公”。 因此，在与他人接触的时候总是会想：“这个人给了我什么？”</p></li><li><p>请你考虑一下认可欲求的实质——他人如何关注自己、如何评价自己？又在多大程度上满足自己的欲求？受这种认可欲求束缚的人看似在看着他人，但实际上眼里却只有自己。失去了对他人的关心而只关心“我”，也就是以自我为中心。</p></li><li><p>实际上，不能进行 <strong>课题分离</strong> 、一味拘泥于认可欲求的人也是极其以自我为中心的人。 把对自己的执著（selfinterest）变成对他人的关心（socialinterest）。</p></li><li><p>就像我一直说的那样，阿德勒心理学认为“烦恼皆源于人际关系”。不幸之源也在于人际关系。反过来说就是，幸福之源也在于人际关系。</p></li><li><p>阿德勒认为他自己所叙述的共同体不仅仅包括家庭、学校、单位、地域社会，还包括国家或人类等一切存在；在时间轴上还包括从过去到未来，甚至也包括动植物或非生物。</p></li><li><p>在这里我们再深入考虑一下。如果他人是伙伴，我们生活在伙伴中间，那就能够从中找到自己的“位置”，而且还可以认为自己在为伙伴们一一也就是共同体——做着贡献。像这样把他人看作伙伴并能够从中感到“自己有位置”的状态，就叫共同体感觉。</p></li><li><p>太过亲密就无法正面对话。但是，距离也不可以太远。课题分离不是为了疏远他人，而是为了解开错综复杂的人际关系之线。</p></li><li><p>但是，当对他人大发雷霆的时候，那是“作为整体的我”选择了勃然大怒，绝对不是感情这一独立存在——可以说与我的意志无关——发出了怒吼。在这里，如果把 我 和 感情 分离</p></li><li><p>分开来认为 <strong>感情让我那么做或者受感情驱使</strong> ，那就容易陷入人生谎言。</p></li><li><p>总之就是不可再分的最小单位的意思。那么具体来讲，什么不可以分割呢？ <em><strong>阿德勒反对把精神和身体、理性和感情以及意识和无意识等分开考虑的一切二元论的价值观。</strong></em></p></li><li><p>我改变了，发生变化的只是“我”。作为结果，对方会怎样我不知道，也无法左右，这也是课题分离。当然，随着我的变化——不是通过我的变化——对方也会发生改变。也许很多情况下 对方不得不改变，但那不是目的，而且也可能不会发生。总之，把改变自己当成操纵他人的手段是一种极其错误的想法。</p></li><li><p>即使有人不喜欢你，那也并不是你的课题。并且，“应该喜欢我”或者“我己经这么努力了还不喜欢我也太奇怪了”之类的想法也是一种干涉对方课题的回报式的思维。不畏惧被人讨厌而是勇往直前，不随波逐流而是激流勇进，这才是对人而言的自由。如果在我面前有“被所有人喜欢的人生”和“有人讨厌自己的人生”这两个选择让我选的话，我一定会毫不犹豫地选择后者。比起别人如何看自己，我更关心自己过得如何。也就是想要自由地生活。</p></li><li><p>毫不在意别人的评价、不害怕被别人讨厌、不追求被他人认可，如果不付出以上这些代价，那 就无法贯彻自己的生活方式，也就是不能获得自由。</p></li><li><p>也就是说 <strong>自由就是被别人讨厌</strong> 。</p></li><li><p>如果人际关系中有“回报思想”存在，那就会产生“因为我为你做了这些，所以你就应该给予相应回报”这样的想法。当然，这是一种与课题分离相悖的思想。我们既不可以寻求回报，也不可以受其束缚。</p></li><li><p>假如你会进行课题分离又会如何呢？也就是说，无论上司怎么蛮不讲理地乱发脾气，那都不是 “我”的课题。毫不讲理这件事情是上司自己应该处理的课题，既没必要去讨好，也没必要委曲求全，我应该做的就是诚实面对自己的人生、正确处理自己的课题。如果你能够这样去理解 ，事情就会截然不同了。</p></li><li><p>人为什么会如此在意别人的视线呢？阿德勒心理学给出的答案非常简单，那就是因为你还不会进行课题分离。把原本应该是别人的课题也看成是自己的课题。</p></li><li><p>关于自己的人生你能够做的就只有“选择自己认为最好的道路”。另一方面，别人如何评价你的选择，那是别人的课题，你根本无法左右。 信任这一行为也需要进行课题分离。信任别人，这是你的课题。但是，如何对待你的信任，那 就是对方的课题了。如果不分清界限而是把自己的希望强加给别人的话，那就变成粗暴的“干 涉”了。</p></li><li><p>青年：辅导顾问不改变被辅导者的人生吗？<br>哲人：能够改变自己的只有自己。</p></li><li><p>接受心理咨询辅导之后，被辅导者下什么样的决心、是否改变生活方式，这都是 被辅导者本人 的课题，辅导顾问不能干涉。</p></li><li><p>辨别究竟是谁的课题的方法非常简单， <strong>只需要考虑一下“某种选择所带来的结果最终要由谁来承担？</strong></p></li><li><p>基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉，或者自己的课题被别人妄加干涉。只要能够进行课题分离，人际关系就会发生巨大改变。</p></li><li><p>这种事任何人都做不到。无论我们走到哪里都被他人包围着，都是活在与他人的关系之中的社会性的“个人”，无论如何都逃不出人际关系这张坚固的大网。阿德勒所说的 <strong>一切烦恼皆源于人际关系</strong> 这句话真可谓是真知灼见啊。</p></li><li><p><strong>货币是被铸造的自由。</strong></p></li><li><p>我也承认人生谎言。我害怕与人打交道，不想在人际关系中受伤，所以就想回避人生课题。正因为如此才摆出了这样那样的借口。</p></li><li><p>我们人类并不是会受原因论所说的精神创伤所摆弄的脆弱存在。从目的论的角度来讲，我们是用自己的手来选择自己的人生和生活方式。我们有这种力量。</p></li><li><p>也就是“不在于被给予了什么，而在于如何去使用被给予的东西” 决定你的生活方式（人生状态）的不是其他任何人，而是你自己这一事实。</p></li><li><p>这是因为那个人已经下定决心要找机会 结束这种关系 ，继而正在搜集结束关系的材料，所以才会那样感觉。对方其实没有任何改变，只是自己的 目的 变了而已。人就是这么任性而自私的生物，一旦产生这种想法，无论怎样都能发现对方的缺点。即使对方是圣人君子一样的人物，也能够轻而易举地找到对方值得讨厌的理由。正因为如此，世界才随时可能变成危险的所在，人们也就有可能把所有他人都看成 敌人 。 那并不是因为无法容忍A的缺点才讨厌他，而是你先有 要讨厌A 这个目的，之后才找出了符合这个目的的缺点。</p></li><li><p>人根本不可能一个人活着，只有在社会性的环境之下才能成为 个人 。因此，阿德勒心理学把作为个人的 自立 和在社会中的 和谐 作为重大目标。</p></li><li><p>另一方面，束缚是想要支配对方的表现，也是一种基于不信任感的想法。与一个不信任自己的 人处在同一个空间里，那就根本不可能保持一种自然状态。阿德勒说：“如果想要和谐地生活在一起，那就必须把对方当成平等的人。”</p></li><li><p>并不是积极地去肯定花心。请你这样想，如果在一起感到苦闷或者紧张，那即使是恋爱关系也不能称之为爱。当人能够感觉到“与这个人在一起可以无拘无束”的时候，才能够体会到爱。 <strong>既没有自卑感也不必炫耀优越性，能够保持一种平静而自然的状态。真正的爱应该是这样的。</strong></p></li><li><p>但是，阿德勒不同意束缚对方这一点。如果对方过得幸福，那就能够真诚地去祝福，这就是爱 。相互束缚的关系很快就会破裂。</p></li><li><p>当然可以。只要你变了，周围也会改变。必须要有所改变。阿德勒心理学不是改变他人的心理学，而是追求自我改变的心理学。不能等着别人发生变化，也不要等着状况有所改变，而是由你自己勇敢迈出第一步。</p></li><li><p>而且，在这个阶段的人际关系方面出现问题的，就是那些被称为自闭的人。</p></li><li><p><strong>工作上的人际关系可以说门槛最低</strong> 。工作上的人际关系因为有着成果这一简单易懂的共通目标，即使有些不投缘也可以合作或者说必须合作；而且，因“工作”这一点结成的关系，在下班或者转行后就又可以变回他人关系。</p></li><li><p>原本主张的对错与胜负毫无关系。如果你认为自己正确的话，那么无论对方持什么意见都应该 无所谓。但是，很多人都会陷入权力之争，试图让对方屈服。正因为如此，才会认为 承认自己的错误 就等于 承认失败 。</p></li><li><p>关于权力之争，还有一点需要注意。那就是无论认为自己多么正确，也不要以此为理由去责难对方。这是很多人都容易陷落进去的人际关系圈套。</p></li><li><p>你似乎还没有真正理解。 <em><strong>不是不能发怒，而是没必要依赖发怒这一工具。</strong></em></p></li><li><p>孩子正是因为知道这一点，所以才会出现问题行为。孩子并不是受过去原因（家庭环境）的影 响，而是为了达到现在的目的（报复父母）。</p></li><li><p>这种情况下，对方的目的是什么呢？是纯粹想要讨论政治吗？不是。对方只是想要责难挑衅你，通过权力之争来达到让不顺眼的你屈服的目的。这个时候你如果发怒的话，那就是正中其下怀，关系会急剧转入权力之争。</p></li><li><p><em><strong>因私愤而流露的发怒只不过是为了让别人屈服的一种工具而己。</strong></em> 先生您说“人是在捏造愤怒的感情”</p></li><li><p>如果能够体会到“人人都是我的伙伴”，那么对世界的看法也会截然不同。不再把世界当成危险的所在，也不再活在不必要的猜忌之中，你眼中的世界就会成为一个安全舒适的地方。人际关系的烦恼也会大大减少。</p></li><li><p>当某人陷入困难的时候你随时愿意伸出援手，那他对你来说就是可以称为伙伴的存在。</p></li><li><p>而且，就像热衷于照镜子的少年一样，这实际上也是自我意识过剩的反应。世上的人其实并不关注我。即使我在大街上倒立也不会有人留意！</p></li><li><p>不是单纯的的竞争对手。不知不觉就会把他人乃至整个世界都看成“敌人”</p></li><li><p><strong>我们都走在一个并不存在纵轴的水平面上，我们不断向前迈进并不是为了与谁竞争。价值在于不断超越自我。</strong></p></li><li><p>就知识、经验或者责任来讲也许存在着差异。也许孩子不能很好地系鞋带、不能解开复杂的方程式或者是在发生问题的时候不能像成人那样去负责任。但是，人的价值并不能用这些来决定 。我的回答仍然一样：<strong>所有的人都是“虽然不同但是平等”的。</strong></p></li><li><p>人都各有差异，这种“差异”不关乎善恶或优劣。因为不管存在着什么样的差异，我们都是平等的人。</p></li><li><p>健全的自卑感不是来自与别人的比较，而是来自与“理想的自己”的比较。</p></li><li><p>阿德勒说：“在我们的文化中，如果要问谁最强大，那答案也许应该是婴儿。婴儿其实总是处于支配而非被支配的地位。”婴儿就是通过其弱势特点来支配大人。并且，婴儿因为弱势所以不受任何人的支配。</p></li><li><p>通过这种方式，我就可以变得比他人更有优势、更加“特别”。生病的时候、受伤的时候、失恋难过的时候，在诸如此类情况下，很多人都会用这种态度来使自己变成“特别的存在”。</p></li><li><p>哲人：是的。如果真正地拥有自信，就不会自大。正因为有强烈的自卑感才会骄傲自大，那其实是想要故意炫耀自己很优秀。担心如果不那么做的话，就会得不到周围的认可。这完全是一种优越情结。<br>青年：……也就是说，自卑情结和优越情结从名称上来看似乎是正相反的，但实际上却有着密切的联系？</p></li><li><p>不过，借助权势的力量来抬高自己的人终究是活在他人的价值观和人生之中。这是必须重点强调的地方。</p></li><li><p>哲人：虽然苦于强烈的自卑感，但却没有勇气通过努力或成长之类的健全手段去进行改变。即便如此，又没法忍受“因为有A所以才做不到B”之类的自卑情结，无法接受“无能的自己” 。如此一来，人就会想要用更加简便的方法来进行补偿。<br>青年：怎么做呢？<br>哲人：表现得好像自己很优秀，继而沉浸在一种虚假的优越感之中。</p></li><li><p>青年：不想成功？这是什么道理啊？<br>哲人：简单地说就是害怕向前迈进或者是不想真正地努力。不愿意为了改变自我而牺牲目前所享受的乐趣——比如玩乐或休闲时间。也就是拿不出改变生活方式的“勇气”，即使有些 不满或者不自由，也还是更愿意维持现状。</p></li><li><p>自卑感本身并不是坏事。这一点你能够理解吧？就像阿德勒说过的那样，自卑感也可以成为促成努力和进步的契机。例如，虽然对学历抱有自卑感，但若是正因为如此，才下定“我学历低 所以更要付出加倍的努力”之类的决心，那反而成了好事。 　　而另一方面，自卑情结是指把自己的自卑感当作某种借口使用的状态。具体就像“我因为学历低所以无法成功”或者“我因为长得不漂亮所以结不了婚”之类的想法。像这样在日常生活中大肆宣扬“因为有A所以才做不到B”这样的理论，这已经超出了自卑感的范畴，它是一种 <strong>自卑情结。</strong></p></li><li><p>阿德勒说“无论是追求优越性还是自卑感，都不是病态，而是一种能够促进健康、正常的努力和成长的刺激”</p></li><li><p>与此相对应的就是自卑感。人都处于追求优越性这一“希望进步的状态”之中，树立某些理想</p></li><li><p>或目标并努力为之奋斗。同时，对于无法达成理想的自己就会产生一种自卑感。</p></li><li><p>首先，人是作为一种无力的存在活在这个世界上。并且，人希望摆脱这种无力状态，继而就有了普遍欲求。阿德勒称其为“追求优越性”。</p></li><li><p>青年：……如果这个世界上只有我一个人存在？<br>哲人：是的。也就是说，价值问题最终也可以追溯到人际关系上。</p></li><li><p>价值必须建立在社会意义之上。即使1美元纸币所承载的价值是一种常识（共通感觉），那它也不是客观意义上的价值。</p><blockquote><p>但是社会共识不因主观而改变</p></blockquote></li><li><p>困扰我们的自卑感不是“客观性的事实”而是“主观性的解释”</p></li><li><p>之所以感觉孤独并不是因为只有你自己一个人，感觉自己被周围的他人、社会和共同体所疏远才会孤独。我们要想体会孤独也需要有他人的存在。也就是说，人只有在社会关系中才会成为 “个人”</p></li><li><p>在人际关系中根本不可能不受伤。只要涉入人际关系就会或大或小地受伤，也会伤害别人。阿 德勒曾说“要想消除烦恼，只有一个人在宇宙中生存”。但是，那种事情根本就无法做到。</p><blockquote><p>美好的结局不一定总会有</p></blockquote></li><li><p>与朋友一起和那个男孩出去玩儿，最终那个男孩先向她告白了。</p></li><li><p><em><strong>“无论之前的人生发生过什么，都对今后的人生如何度过没有影响。”决定自己人生的是活在 “此时此刻”的你自己。</strong></em></p></li><li><p>青年：梦也许会破灭啊！<br>哲人：但那又怎样呢？应该去做——这一简单的课题摆在面前，但却不断地扯出各种“不能做的理由”，你难道不认为这是一种很痛苦的生活方式吗？梦想着做小说家的他，正是“自己”把人生变得复杂继而难以获得幸福。</p></li><li><p>实际上，他是想通过不去比赛这一方式来保留一种“如果做的话我也可以”的可能性，即不愿出去被人评价，更不愿去面对因作品拙劣而落选的现实。他只想活在“只要有时间我也可以、 只要环境具备我也能写、自己有这种才能”之类的可能性中。或许再过5年或者10年，他又会 开始使用“已经不再年轻”或者“也已经有了家庭”之类的借口。</p></li><li><p>要想改变生活方式需要很大的“勇气”。面对变化产生的“不安”与不变带来的“不满”，你 一定是选择了后者</p></li><li><p>问题不在于过去而在于现在。现在你了解了生活方式。如果是这样的话，接下来的行为就是你 自己的责任了。无论是继续选择与之前一样的生活方式还是重新选择新的生活方式，那都在于你自己。</p></li><li><p>某人如何看“世界”，又如何看“自己”，把这些“赋予意义的方式”汇集起来的概念就可以 理解为生活方式。从狭义上来讲可以理解为性格：从广义上来说，这个词甚至包含了某人的世界观或人生观。</p></li><li><p>这个世界上充斥着违法或犯罪之类的种种恶行。但是，纯粹意义上想要做“恶=没好处的事” 的人根本没有。</p></li><li><p>重要的不是被给予了什么，而是如何去利用被给子的东西</p></li><li><p>人并不受过去的原因所左右，而是朝着自己定下的目标前进，这就是哲人的主张。哲人所倡导的“目的论”是一种彻底颠覆正统心理学中的因果论的思想</p></li><li><p>问题不在于“发生了什么”，而在于“如何诠释”</p></li><li><p>我并不是否定感情的存在。任何人都有感情，这是理所当然的事情。但是，如果你说“人是无 法抵抗感情的存在”，那我就要坚决地否定这种观点了。我们并不是在感情的支配下而采取各 种行动。而且，在“人不受感情支配”这个层面上，进而在“人不受过去支配”这个层面上， 阿德勒心理学正是一种与虚无主义截然相反的思想和哲学。</p></li><li><p>你并不是“受怒气支配而大发雷霆”，完全是“为了大发雷霆而制造怒气”。也就是说，为了达到大发雷霆这个目的而制造出来愤怒的感情。</p></li><li><p>所谓愤怒其实只是可放可收的一种“手段”而已。它既可以在接电话的瞬间巧妙地收起，也可 以在挂断电话之后再次释放出来。这位母亲并不是因为怒不可遏而大发雷霆，她只不过是为了用高声震慑住女儿，进而使其听自己的话才采用了愤怒这种感情。</p><blockquote><p>久而久之才会形成习惯</p></blockquote></li><li><p><em><strong>愤怒都是捏造出来的</strong></em></p></li><li><p>他心有不满，而且也并不幸福。但是，他的确是按照“目的”而采取的行动。不仅仅是他，我 们大家都是在为了某种“目的”而活着。这就是目的论。</p></li><li><p>“任何经历本身并不是成功或者失败的原因。我们并非因为自身经历中的刺激——所谓的心理 创伤——而痛苦，事实上我们会从经历中发现符合自己目的的因素。决定我们自身的不是过去 的经历，而是我们自己赋予经历的意义。”</p></li><li><p>感冒原因是穿得薄也好、淋了雨也好，这都无所谓。问题是现在正受着高烧的折磨这个事实， 关键在于症状。如果是医生的话，就应该好好开药或者打针，以一些专业性的处理来进行治疗 。</p></li><li><p>你的朋友是先有了“不出去”这个目的，之后才会为了达到这个目的而制造出不安或恐惧之类 的情绪。阿德勒心理学把这叫作“目的论”。</p></li><li><p>如果一味地关注过去的原因，企图仅仅靠原因去解释事物，那就会陷入“决定论”。也就是说 ，最终会得出这样的结论：我们的现在甚至末来全部都由过去的事情所决定，而且根本无法改 变。</p></li><li><p>我感觉心灵鸡汤的真理背后，存在着某些不合理的东西，甚至能嗅到一些精神毒品的气味在里 面，但无法清晰言说；那种反感在那里，我亦无从用我熟知的心理学理论去解释它。</p></li><li><p>第三个束缚，来自未来。很多人目标远大，觉得只有当上CEO、迎娶白富美、走上人生巅峰， 人生才真的开始，现在的生活还不叫“人生”，只能算是在通往人生的路上。 <strong>当我们这么想的时候，我们就把现在贬低成了实现未来的工具。但现在却是我们唯一真正经历和拥有的。</strong></p></li><li><p><strong>在阿德勒眼中，理想的人际关系大概是“我爱你，但与你无关”。</strong> 他认为每个人的课题都是分离又独特的。我怎么爱你，这是我的课题，而你要不要接受我的爱，这是你的课题。</p></li><li><p>每一年我都更为信服弗洛伊德和他的后继者的理念（与我而言主要是英国精神分析家比昂）， 但这样的逐步信任也隐含着一种危险——那就是过分认同并忠诚于一种信条，不知不觉间开始通过一根管子去观察世界和人生（要命的是这根管子比你想象的要更细，哪怕是你经常反省这 一点）。换句话说，我可能中弗洛伊德的毒太深了（尽管我尝试着多学学荣格以稍稍解毒，结 果发现自己更沉醉于内心和过去的世界），在这个时候读到的阿德勒的确是一剂及时的良药。 阿德勒对于当下的重视，对于人际的理解，对于勇气和决定的重要性的再三确认……</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 书摘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 心理学 </tag>
            
            <tag> 哲学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python</title>
      <link href="/python/"/>
      <url>/python/</url>
      
        <content type="html"><![CDATA[<ol><li><p>求数组某行某列的最大值(最小值)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求所有数字中的最大值</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一列的最大值组成列表</span><span class="token triple-quoted-string string">'''对a=a[n0][n1],axis=0时,对应n0已经确定下来,即n0取值定为0,1,遍历n0.所以此时的amax就是固定n1,amax[n1] = max(a[0][n1],a[1][n1]),表现为按列取最大值'''</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>amax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一行的最大值组成列表</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">5[2 5][5 3]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>矩阵点积与向量外积</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>d <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 就是数学上的矩阵乘法</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>c<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token triple-quoted-string string">'''向量外积,也就是m维向量和n维向量之间,做(m,1)和(1,n)到(m,n)的矩阵乘法,有效解决numpy中(k,)维向量的歧义'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">[[15 20] [11 16]][[ 6 15] [ 8 20]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>矩阵(多维数组)求和</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npa <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 所有维度求和</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一列的和</span><span class="token triple-quoted-string string">'''对a=a[n0][n1],axis=0时,对应n0已经确定下来,即n0取值定为0,1,遍历n0.所以此时的sum就是固定n1,sum[n1] = a[0][n1]+a[1][n1],表现为按列求和'''</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 求每一行的和</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-output" data-language="output"><code class="language-output">10[2 8][5 5]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 自学笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>复杂系统与复杂网络</title>
      <link href="/fu-za-xi-tong-yu-fu-za-wang-luo/"/>
      <url>/fu-za-xi-tong-yu-fu-za-wang-luo/</url>
      
        <content type="html"><![CDATA[<h2 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h2><p>参考用书<br>1、Networks Crowds and Markets: Reasoning about a Highly Connected World David Easley and Jon Kleinberg 2010年 Cambridge University Press</p><p>课程教师信息<br>课程首席教授郑晓龙研究员，在社会计算、知识图谱和大数据解析学的基础理论研究、关键技术研发和系统平台建设等方面系取得了丰富的研究成果。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul><li>强弱关系：紧密频繁或偶然</li><li>结构洞</li><li>嵌入性：在四边形ABCD中连接AC，反映了AC之间关系的可靠性</li><li>桥：AB间的唯一路径 -&gt; 捷径：去除AB连边会让他们距离增加2以上</li><li>社会资本：人们在社会（社会网络）结构中所处的位置给他们带来的资源<ul><li>契结资本：强连接，表达性行动，情感</li><li>工具资本：弱连接，工具性</li></ul></li><li>正关系和负关系</li><li>结构平衡（三者皆是敌人导致敌人的敌人仍是敌人）</li><li>网络影响力：依赖性，排他性，饱和性，介数</li><li>核心-外围结构</li><li>网络社区发现：节点要求，集合要求，互不重叠，层次化社区结构，如何提取隐藏的社区结构</li><li><strong>激活扩散理论</strong> ：一个概念被激活，其效应可以扩散到与其相关联的其他节点，<em>NLP相关</em></li><li>注意力网络：近因，首因，边际递减效应</li><li>流行语传播网络：信息模因（Meme）<ul><li>信息在人群中传播就像基因一样，会不断复制和演化</li><li>基于网络的群体情感行为演化</li></ul></li><li>网络中的同质现象：由节点主动选择（选择相似特征【或自己所喜欢的特征？】的朋友）和被动影响（成朋友之后的影响）交错而成</li><li>从众行为：信息效应，直接受益效应<ul><li>信息效应：根据有限的信息进行合理推理，和模仿顺从不同，“信息级联”</li><li>理性状态下的认知失衡</li></ul></li><li>社会影响：行为，态度，信念</li><li>影响力对抗网络</li><li>大脑不擅长概率问题，擅长因果问题</li></ul><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><ul><li>动态网络</li><li>现有社交网络（推特、微博等数据集）中缺乏负关系（对抗敌对）的挖掘与应用</li><li>无向图中负号偶数是平衡，有向图中负号奇数是有效调节</li><li>同质性，“圈层”</li><li>激活扩散中，概念如何更高效准确的储存和调用（进化？）</li><li>因果就是 贝叶斯+神经网络</li><li>如果用BERT对学习出句子的向量化表达，再取平均可以当作帖子的向量化表达，然后求余弦相似度，设置阈值进行连边，再把极大连通分量找出来，可以找出对哪些话题经过了大量重复的激烈讨论，我还有个不成熟的idea，这个结合上发帖时间是不是可能用来挖掘“水军”的重复发帖。</li></ul><h2 id="课程研讨记录"><a href="#课程研讨记录" class="headerlink" title="课程研讨记录"></a>课程研讨记录</h2><ul><li>因果涌现</li><li>有符号网络 级联传播 对抗</li><li>图同构 图的相似性</li><li>研究尺度的分离 宏观系统和微观个体</li><li>金融耦合</li><li>长文本匹配</li><li>预测 就是 低维到高维 是高维空间的点（时间当作新维度） 那点之间的边是什么 是不是更高维的点  <strong>低维线到高维点</strong></li><li>因果+推荐系统</li><li>金融投资组合 最小生成树</li><li>灾和害是两个概念</li><li>临界值 涌现</li><li>图数据库neoGJ</li><li>基于特定任务的复杂网络</li><li>语言是线性的，但是想法是非线性的</li></ul><h2 id="我的研讨草稿"><a href="#我的研讨草稿" class="headerlink" title="我的研讨草稿"></a>我的研讨草稿</h2><p>我们小组目前在做的方向是舆情分析和社会复杂系统分析，我们平时用到复杂网络的地方就相当的多。大家上了这么多堂课，学了这么多理论概念，我正好就来给大家介绍一点这些理论的基础应用工作。就比如一个舆情事件，我们怎么分析它的发展脉络，就以之前热度很高的红十字会有关一系列事件，首先肯定是获取元数据，根据关键词抓取一些新闻报道，微博帖子，知乎回答之类，这些基本都是一些文本形式，我们可以先用nlp的技术做个切词，再用一些textrank tfidf之类的方法提取每个帖子前几的关键词，那么第一，我们就可以构建出一个关键词网络，关键词作为节点，在帖子中的共现关系做边，共现频率当权重，就有第一个关键词共现网络，我们可以根据这个网络做一个louvain算法社区划分，再分析几个社区的最大中心性的节点，比如第一个社区，最大中心性的是捐款，第二个社区呢，最大中心性的是学校，孩子之类的，就把这一系列事件分成了两大主要组别。我们还可以用帖子做节点，共享关键词做连边，我们可以根据介数中心性啊，pagerank啊，度啊最大的几个节点，也就是帖子挖掘出来，这就可以揭示这一系列相关舆情事件的主要内容。还可以对这个网络找割点，比如一个帖子“中国红会为何否认郭美美事件”是割点，那比如它左边的是郭美美，红监会之类的事件，右边是地震，捐款之类的帖子，就可以看到不同舆情子事件中的关联。如果用BERT对学习出句子的向量化表达，再取平均可以当作帖子的向量化表达，然后求余弦相似度，设置阈值进行连边，再把极大连通分量找出来，可以找出对哪些话题经过了大量重复的激烈讨论，我还有个不成熟的idea，这个结合上发帖时间是不是可能用来挖掘“水军”的重复发帖。那如果是微博的帖子，还有很多回复现象，对回复文本做情感分析，得到情感极性1，-1，0，有了这些，又可以构造出一个有符号的回复网络，边代表回复关系，符号就是情感极性，然后就可以做统计啊，研究互动关系啊，互动持续时间分布之类的。就是总之复杂网络其实是一个相当有意义的学科，学的每一个概念，可能都会发挥很重要的作用。</p>]]></content>
      
      
      <categories>
          
          <category> 课程笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复杂网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention Is All You Need</title>
      <link href="/attention-is-all-you-need/"/>
      <url>/attention-is-all-you-need/</url>
      
        <content type="html"><![CDATA[<p>Transformer: 基于多头自注意力机制进行序列到序列的encoder-decoder架构，完全摒弃循环层和卷积层，nlp领域大山头！</p><h2 id="论文十问"><a href="#论文十问" class="headerlink" title="论文十问"></a>论文十问</h2><p>由 <a href="https://readpaper.com/"><em>ReadPaper平台</em></a> 提出，有助于总结信息，构建认知模型。</p><blockquote><ol><li>论文试图解决什么问题？</li></ol><blockquote><p>在机器翻译、句法分析等nlp任务上取得好成绩，进行更准确的序列转化（编-解码）。出发点在于基于CNN、RNN的模型在长距离依赖下的限制，更好的进行并行计算。</p></blockquote><ol start="2"><li>这是否是一个新的问题？</li></ol><blockquote><p>不是新问题，但是是一个全新的思路。</p></blockquote><ol start="3"><li>这篇文章要验证一个什么科学假设？</li></ol><blockquote><p>在序列到序列学习中，用（多头）自注意力机制替代循环层、卷积层，可以取得很好的结果。</p></blockquote><ol start="4"><li>有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</li></ol><blockquote><p>暂略</p></blockquote><ol start="5"><li>论文中提到的解决方案之关键是什么？</li></ol><blockquote><p>用（多头）自注意力机制完全替代循环层和卷积层、位置编码、适当位置加入前馈神经网络、注意力机制的多层灵活运用。</p></blockquote><ol start="6"><li>论文中的实验是如何设计的？</li></ol><blockquote><p>在公开数据集上训练，和其他模型作比较，并控制变量评估了模型中各个部分所带来的精度影响。</p></blockquote><ol start="7"><li>用于定量评估的数据集是什么？代码有没有开源？</li></ol><blockquote><p>WMT 2014 English-German dataset，WMT 2014 English-French dataset，Wall Street Journal (WSJ) portion of the Penn Treebank（宾州树库），已经在 <a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a> 上开源模型。</p></blockquote><ol start="8"><li>论文中的实验及结果有没有很好地支持需要验证的科学假设？</li></ol><blockquote><p>实验结果相当乐观，在机器翻译和句法分析等nlp任务上取得了截止论文发表时最高的评分。</p></blockquote><ol start="9"><li>这篇论文到底有什么贡献？</li></ol><blockquote><p>提出了一套革命式的nlp研究框架。</p></blockquote><ol start="10"><li>下一步呢？有什么工作可以继续深入？</li></ol><blockquote><p>扩展到其他领域（音视频图像，以及其他类型的序列到序列学习领域），模型变种（基本被卷王们做完了）。</p></blockquote></blockquote><p>还可以点击这里参考<a href="https://readpaper.com/paper/2963403868/questions-detail?questionId=534901540122656768">公开回答</a></p><h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p><a href="Transformer.xmind">思维导图下载链接</a></p><p><img src="/attention-is-all-you-need/Transformer.png" alt="思维导图"></p><table><thead><tr><th><img src="1.jpg" width="300/"></th></tr></thead><tbody><tr><td><center>模型框架图</center></td></tr></tbody></table><table><thead><tr><th><img src="2.jpg" width="300/"></th><th><img src="3.jpg" width="300/"></th></tr></thead><tbody><tr><td><center>注意力模型</center></td><td><center>参数影响测试</center></td></tr></tbody></table><h2 id="资料参考"><a href="#资料参考" class="headerlink" title="资料参考"></a>资料参考</h2><h3 id="深入理解Self-Attention"><a href="#深入理解Self-Attention" class="headerlink" title="深入理解Self-Attention"></a>深入理解Self-Attention</h3><p><a href="attention.pdf">注意力机制(截取自《神经网络与深度学习》邱锡鹏)</a></p><p>向量的内积，其几何意义是什么？</p><p><strong>答：表征两个向量的夹角，表征一个向量在另一个向量上的投影</strong></p><blockquote><p>note:  但是还有两个向量的模长也影响了内积</p><p>进一步的，词向量的模长代表什么？</p></blockquote><hr><p>投影的值大有什么意思？投影的值小又如何？</p><p><strong>投影的值大，说明两个向量相关度高</strong>。</p><p><strong>我们考虑，如果两个向量夹角是九十度，那么这两个向量线性无关，完全没有相关性！</strong></p><hr><p>我们假设 $X = [x_1^T;x_2^T;x_3^T]$，其中 $X$ 为一个二维矩阵， $x_i^T$为一个行向量（其实很多教材都默认向量是列向量，为了方便举例请读者理解笔者使用行向量）</p><blockquote><p>note:  如果 $X$ 写为 $X = [x_1,x_2,x_3]$, 其中$x_i$都是列向量的形式, 那么公式就变为$\boldsymbol{H}=\boldsymbol{V}\operatorname{softmax}\left(\frac{\boldsymbol{K}^{\top}\boldsymbol{Q}}{\sqrt{D_k}}\right) $ 的形式, 且其中Q,K,V都变为 $WX$ 的形式, 但相应的也不会影响本文分析</p></blockquote><hr><p>$softmax(XX^T)$的意义图解: </p><img src="./v2-179fd393b3aac244ec338767ef5d8d3d_r.jpg" style="zoom:67%;"><hr><p>我们回想 $Softmax$ 的公式，$Softmax$ 操作的意义是什么呢？</p><p><strong>答：归一化</strong></p><blockquote><p>note:  这里是对每一行做softmax归一化，归一化之后实际上得到了“早”，“上”，“好”三个字在“早”字上的投影长度的比例关系</p></blockquote><hr><img src="./v2-71069dfdaf4758a037bdddc56d2a5fc5_r.jpg" style="zoom:67%;"><hr><p>在新的向量中，每一个维度的数值都是由三个词向量在这一维度的数值加权求和得来的</p><blockquote><p>note:  上述的比例关系再乘回原向量“早”，“上”，“好”再求和得到了什么？看不到几何意义，但能一定程度上反应相关性，或者说包含下了整个语句的信息。</p></blockquote><hr><p>一张更形象的图是这样的，图中右半部分的颜色深浅，其实就是我们上图中黄色向量中数值的大小，意义就是单词之间的相关度（<strong>回想之前的内容，相关度其本质是由向量的内积度量的</strong>）</p><blockquote><p>note:  还得看词向量的意义所在，词向量内积，夹角等等的含义</p></blockquote><hr><img src="./v2-f85c81cbb259b80c3644a16e005679be_r.jpg" style="zoom:67%;"><hr><img src="./v2-55d08f662a489739c3220486de095e12_r.jpg" style="zoom:67%;"><blockquote><p>note:  做的假设是X是行向量代表词语，右乘一个矩阵才能体现出对行向量做线性变换</p></blockquote><hr><p><img src="/attention-is-all-you-need/v2-da928d89f18a138c259cc42b7cc582cd_r.jpg"></p><hr><p>其实，许多文章中所谓的<code>Q</code> <code>K</code> <code>V</code>矩阵、查询向量之类的字眼，其来源是 $X$ 与矩阵的乘积，<strong>本质上都是</strong> $X$ <strong>的线性变换</strong>。</p><hr><p>为什么不直接使用 $X$ 而要对其进行线性变换？</p><p>当然是为了提升模型的拟合能力，矩阵 $W$ 都是可以训练的，起到一个缓冲的效果。</p><hr><p>假设 $Q,K$ 里的元素的均值为 0，方差为 1，那么 $A=QK^T$ 中元素的均值为 0，方差为 $d$. 当 $d$ 变得很大时， $A$ 中的元素的方差也会变得很大，如果 $A$ 中的元素方差很大，那么 $Softmax(A)$ 的分布会趋于陡峭 (分布的方差大，分布集中在绝对值大的区域)。</p><hr><p>总结一下就是 $Softmax(A)$ 的分布会和 $d$ 有关。因此 $A$ 中每一个元素除以$\sqrt{d_k}$ 后，方差又变为 1。这使得 $Softmax(A)$ 的分布 “陡峭” 程度与 $d$ 解耦，从而使得训练过程中梯度值保持稳定。</p><hr><p>最后再补充一点，<strong>对 self-attention 来说，它跟每一个 input vector 都做 attention，所以没有考虑到 input sequence 的顺序</strong>。更通俗来讲，大家可以发现我们前文的计算每一个词向量都与其他词向量计算内积，得到的结果丢失了我们原来文本的顺序信息。对比来说，LSTM 是对于文本顺序信息的解释是输出词向量的先后顺序，而我们上文的计算对 sequence 的顺序这一部分则完全没有提及，你打乱词向量的顺序，得到的结果仍然是相同的。</p><p>这就牵扯到 Transformer 的位置编码了。</p><blockquote><p>To this end, we add “positional encodings” to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension d-model as the embeddings, so that the two can be summed. </p></blockquote><h3 id="Transformer里的Mask机制"><a href="#Transformer里的Mask机制" class="headerlink" title="Transformer里的Mask机制"></a>Transformer里的Mask机制</h3><p>1.padding mask</p><p>在 encoder 和 decoder 两个模块里都有 padding mask，位置是在softmax之前，<strong>为什么</strong>要使用 padding mask，是<strong>因为由于 encoder 和 decoder 两个模块都会有各自相应的输入，但是输入的句子长度是不一样的，计算 attention score 会出现偏差</strong>，为了<strong>保证句子的长度一样所以需要进行填充</strong>，<strong>但是</strong>用 0 填充的位置的信息是完全没有意义的（多余的），经过 softmax 操作<strong>也会有对应的输出，会影响全局概率值</strong>，因此我们<strong>希望这个位置不参与后期的反向传播过程</strong>。以此避免最后影响模型自身的效果，既在<strong>训练时将补全的位置给 Mask 掉</strong>，也就是在这些位置上补一些无穷小（负无穷）的值，经过 softmax 操作，这些值就成了 0，就不在影响全局概率的预测。</p><p><a href="https://zhuanlan.zhihu.com/p/353365423">pytorch nn.Transformer 的 mask 理解 - 知乎 (zhihu.com)</a>padding mask 讲得比较细</p><hr><p>2.Sequence MASK</p><p><strong>sequence MASK 是只存在 decoder 的第一个 mutil_head_self_attention 里</strong>，为什么这样做？是因为在测试验证阶段，模型并不知道当前时刻的输入和未来时刻的单词信息。也就是对于一个序列中的第 i 个 token 解码的时候只能够依靠 i 时刻之前 (包括 i) 的的输出，而不能依赖于 i 时刻之后的输出。因此我们要采取一个遮盖的方法 (Mask) 使得其在<strong>计算 self-attention 的时候只用 i 个时刻之前的 token 进行计算</strong>。</p><p>举例：“我爱中国共产党”，假如要预测 “中” 这个词，那么当前时刻的输入就是 “我” 以及 “爱” 的输入的叠加，一部分来自 “ 我 “的信息输出，一部分来自” 爱”的信息输出，如果没有 mask 将后面的单词信息遮住，那么后面的单词对要预测的这个字 “中” 也会有相应的信息贡献，在训练的时候整个句子的前后字词的位置是已知的，所以不遮挡模型也是可以运行的，因为本身模型输入时就已经知道了句子的整个信息（也就是 ground truth embeding）。 但是在进行模型预测（测试新的输入句子）时，输入的句子是未知的，随机的，模型不知道句子的信息，只能通过上一层的输出和原始的输入知道要预测字的前一个信息，进而依次预测后面的字的信息。这就造成了在训练时模型多训练了 “中” 后面的词，增加了训练时间，消耗了本没必要的空间及时间。在一开始训练时就 mask 掉，节省时间的同时也降低了过拟合的风险，提高了模型泛化能力。<a href="https://zhuanlan.zhihu.com/p/368592551" title="浅析Transformer训练时并行问题 - 知乎 (zhihu.com)">浅析 Transformer 训练时并行问题 - 知乎 (zhihu.com)</a><strong>Sequence mask 讲得比较细</strong></p><hr> <img src="./1ae1c2a03b12b6b481151e7bad0d2332.png" style="zoom: 50%;"><hr><p>3.【Pytorch】Transformer 中的 mask ——<a href="https://zhuanlan.zhihu.com/p/435782555">转载自链接</a></p><ul><li>由于 Transformer 的模型结构，在应用 Transformer 的时候需要添加 mask 来实现一些功能。<ul><li>如 Encdoer 中需要输入定长序列而 padding，可以加入 mask 剔除 padding 部分</li><li>如 Decoder 中为了实现并行而输入完整序列，需要加上 mask 剔除不应感知到的部分序列</li></ul></li><li>在一些更灵活的应用中，有时候需要设计一些 mask 形式来调整可利用信息源的范围。因此，本文以官网 Transformer 做文本翻译为例 <a href="https://link.zhihu.com/?target=https://pytorch.org/tutorials/beginner/translation_transformer.html">官网翻译示例</a>，梳理一下 Pytorch 实现的 Transformer 是如何做 mask 操作的。<a href="https://blog.csdn.net/qq_35169059/article/details/101678207">(164 条消息) Transformer 的矩阵维度分析和 Mask 详解_我最怜君中宵舞的博客 - CSDN 博客_transformer 中的 mask// 讲清楚了训练可以并行，推理和测试的时候不能并行的原因</a></li></ul><hr><h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2><ol><li>自注意力机制(Q,K,V结构)本质是向量信息的交叉（交互）？是否流于形式，可以简化吗？可以拓展吗？<br> $ Q K^T = X W_q W_k^T X^T $, 其中 $ X = [X_1;X_2;…X_n] $…</li><li>positional encodings直接和word embeddings做和，是否不妥，实际含义为何？（词本身的含义与位置相关？如果用依存句法分析树来编码？），用向量拼接的方式怎么样（存在维数控制问题？）</li></ol><h2 id="原文-amp-个人标注"><a href="#原文-amp-个人标注" class="headerlink" title="原文 &amp; 个人标注"></a>原文 &amp; 个人标注</h2><p><a href="1.pdf">PDF下载链接</a></p><div class="row">    <embed src="1.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="外文写作"><a href="#外文写作" class="headerlink" title="外文写作"></a>外文写作</h2><h3 id="用词"><a href="#用词" class="headerlink" title="用词"></a>用词</h3><table><thead><tr><th align="left">词语</th><th align="left">文中释义</th><th align="left">词语</th><th align="left">文中释义</th></tr></thead><tbody><tr><td align="left">auto-regressive</td><td align="left">自动回归的</td><td align="left">albeit</td><td align="left">尽管</td></tr><tr><td align="left">stacked</td><td align="left">堆叠的</td><td align="left">residual connection</td><td align="left">残差连接</td></tr><tr><td align="left">parallel</td><td align="left">并行</td><td align="left">simultaneously</td><td align="left">同时</td></tr><tr><td align="left">additive attention</td><td align="left">累积注意力</td><td align="left">compatibility function</td><td align="left">兼容函数</td></tr><tr><td align="left">in magnitude</td><td align="left">在规模上</td><td align="left">concatenate</td><td align="left">连接</td></tr><tr><td align="left">mimics</td><td align="left">模仿</td><td align="left">hypothesize</td><td align="left">假定</td></tr><tr><td align="left">extrapolate to</td><td align="left">外推到</td><td align="left">interpretable</td><td align="left">可解释的</td></tr><tr><td align="left">training regime</td><td align="left">训练机制</td><td align="left"></td><td align="left"></td></tr></tbody></table><h3 id="用句"><a href="#用句" class="headerlink" title="用句"></a>用句</h3><blockquote><ul><li>left and right halves of Figure 1</li></ul><blockquote><p>图一的左右半部分</p></blockquote><ul><li>as depicted in Figure 2.</li></ul><blockquote><p>如图二所示</p></blockquote></blockquote><h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>暂待补充</p>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 2017-12 </tag>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> Self-Attention </tag>
            
            <tag> Mask </tag>
            
            <tag> Multi-Head Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>这是<em>网站</em>搭建后<strong>第一篇</strong>测试博客！<code>欢迎</code>来到我的个人网站！</p><p><em><strong>源码</strong></em> 放在<a href="https://github.com/BillZid">github主页</a>上。</p><blockquote><p><del>求你看看</del></p><blockquote><p>多多交流！</p></blockquote></blockquote><hr><h2 id="插入代码"><a href="#插入代码" class="headerlink" title="插入代码"></a>插入代码</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">hello_world</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hello World!"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>还可以<code>print("Hello again!")</code></p><h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><img src="01.jpg" width="30%" height="30%"><center>可爱小天依</center><h2 id="插入pdf"><a href="#插入pdf" class="headerlink" title="插入pdf"></a>插入pdf</h2><div class="row">    <embed src="1.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="插入表格"><a href="#插入表格" class="headerlink" title="插入表格"></a>插入表格</h2><table><thead><tr><th align="left">001</th><th align="left">002</th><th align="left">003</th></tr></thead><tbody><tr><td align="left">数学</td><td align="left">计算机</td><td align="left">管科</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 随笔记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网站测试 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
